# Semester 4
## Verteilte Systeme
### Cloud Computing
- Infrastructure as a Service (IaaS):
Ein Modell für Cloud Computing, bei dem Unternehmen Zugang zu IT-Infrastruktur wie Computersystemen, Speicher und Netzwerken über das Internet erhalten. Alle Stufen ab der Aufsetzung des OS muss der Kunde tragen. Beispiel: Amazon Web Services (AWS), Google Compute Engine und Microsoft Azure
- Platform as a Service (PaaS):
Ein Modell für Cloud Computing, bei dem Unternehmen Zugang zu einer bereitgestellten Plattform erhalten, die es ihnen ermöglicht, Anwendungen und Dienste ohne den Aufwand für die Verwaltung der unterstützenden Infrastruktur (z.B. Servers, Speicher, Netzwerk) zu entwickeln, bereitzustellen und auszuführen. Nur noch die Daten und Applikationen müssen vom Kunden selbst gestellt und konfiguriert werden. Beispiel: AWS Elastic Beanstalk und Google App Engine
- SaaS (Software as a Service):
Ist ein Modell für Cloud Computing, bei dem Anwendungen und Software über das Internet bereitgestellt werden, anstatt lokal auf einem Gerät installiert zu werden. Benutzer greifen über einen Webbrowser oder eine Anwendungs-Schnittstelle auf die Software zu. Beispiel: Gmail

### Merkmale guter Softwarearchitektur
- Kopplung: Kopplung beschreibt wie eng Teilsysteme mit anderen Teilsystemen verbunden sind.
- Kohäsion: beschreibt die Übereinstimmun von Komponenten und Funktionen
- Interoperabilität: beschreibt die Fähigkeit der einzelnen Komponenten in einem Gesamtsystem zusammenzuarbeiten

Wünschenswert ist: lose Kopplung, hohe Kohäsion, hohe Interoperabilität

### RCP 
Ein Konzept der Netzwerkprogrammierung, bei dem ein Programm auf einem Computer einen Prozess auf einem anderen Computer über ein Netzwerk aufruft. RCP stellt eine einfache Möglichkeit bereit, um Aufgaben auf entfernten Computern auszuführen und deren Ergebnisse zurückzuliefern.

### TCP/IP
TCP/IP umfasst zwei Hauptprotokolle: TCP und IP. TCP sorgt für eine zuverlässige Übertragung von Daten, indem es sicherstellt, dass alle Daten vollständig und in der richtigen Reihenfolge empfangen werden. IP sorgt für die Übertragung von Daten zwischen Netzwerken, indem es jedem Datenpaket eine Adresse (IP-Adresse) zuweist, die es identifiziert und an das richtige Ziel überträgt.

### Architekturmodelle
Drei-Schichten-Modell:

- Präsentationsschicht (Presentation Layer): Diese Schicht kümmert sich um die Interaktion mit dem Benutzer und die Darstellung von Daten. Hierbei kann es sich beispielsweise um eine Graphische Benutzeroberfläche oder eine Web-Oberfläche handeln.

- Anwendungsschicht (Application Layer): Diese Schicht ist für die Verarbeitung und Steuerung der Geschäftslogik verantwortlich. Hierbei kann es sich beispielsweise um Datenbankzugriffe oder die Verarbeitung von Geschäftsregeln handeln.

- Datenschicht (Data Layer): Diese Schicht kümmert sich um den Zugriff auf Daten, wie beispielsweise die Verwaltung von Datenbanken.

### Server-Client-Modell
- Das Server-Client-Modell ist ein Architektur-Modell, das eine logische Trennung von Diensten und Ressourcen bereitstellt, die von einem Netzwerk genutzt werden. In diesem Modell wird ein Computer als Server bezeichnet, der einen oder mehrere Dienste bereitstellt, und ein oder mehrere andere Computer als Clients bezeichnet, die diese Dienste nutzen.

- Die Client-Computer senden Anfragen an den Server, um einen Dienst zu nutzen, z.B. um auf eine Datei oder eine Datenbank zuzugreifen. Der Server verarbeitet diese Anfragen und liefert eine Antwort zurück.

### Web-Services
Web-Services sind ein standardsbasiertes Framework für die Kommunikation und den Austausch von Daten über das Internet. Sie bieten eine einfache Möglichkeit, Anwendungen und Dienste von verschiedenen Systemen und Plattformen miteinander zu verbinden und Daten auszutauschen.

Web-Services sind plattformunabhängig, so dass Anwendungen auf verschiedenen Betriebssystemen und in verschiedenen Programmiersprachen implementiert werden können. Dies ermöglicht es Unternehmen, ihre IT-Systeme und Anwendungen zu integrieren und zu verknüpfen, um eine bessere Zusammenarbeit und Effizienz zu erreichen.

### Micro-Services
Die Microservice-Architektur ist ein Ansatz zur Softwareentwicklung, bei dem eine Anwendung als eine Sammlung von kleinen, unabhängigen Diensten organisiert wird, die jeweils eine spezifische Aufgabe ausführen. Im Gegensatz zu Monolithen, bei denen alle Funktionen einer Anwendung in einem einzigen Codeblock enthalten sind, kann jeder Microservice unabhängig entwickelt, bereitgestellt und verwaltet werden.

Bei der Orchestrierung von Microservices werden Tools und Technologien eingesetzt, um die Verwaltung von Microservices zu vereinfachen und zu automatisieren. Diese Tools ermöglichen es Entwicklern, sich auf die Entwicklung von Microservices zu konzentrieren, anstatt sich mit der Verwaltung der Infrastruktur und der Bereitstellung von Microservices zu beschäftigen.

### DNS
DNS ist das "Telefonbuch des Internets". Es enthält Informationen darüber, welche IP-Adresse zu einem bestimmten Domänennamen gehört. Wenn Sie eine Website aufrufen, wenden Sie sich an Ihren DNS-Server, um die IP-Adresse des Servers zu erhalten, auf dem die Website gehostet wird. Anschließend wird eine Verbindung zu diesem Server hergestellt, um die Website anzuzeigen.

## Big Data Storage

### Spark
Apache Spark ist ein Open-Source-Framework für Big-Data-Verarbeitung, das für hohe Leistung und Skalierbarkeit bekannt ist. Es wurde mit dem Ziel entwickelt, die Verarbeitung großer Datenmengen in Echtzeit zu vereinfachen und zu beschleunigen.

Spark verwendet ein in-memory-basiertes Modell, um Daten schneller zu verarbeiten, und bietet eine Reihe von APIs in verschiedenen Programmiersprachen, darunter Scala, Python, Java und R, um Datenanalysen durchzuführen. Es bietet auch eine einfache und intuitive Programmierschnittstelle, die es Entwicklern ermöglicht, Datenanalysen durchzuführen, ohne sich mit den technischen Details von Big Data zu befassen.

### Map reduce
Das MapReduce-Modell besteht aus zwei Hauptkomponenten: Map und Reduce. Der Map-Schritt nimmt eine große Datenmenge als Eingabe und wandelt sie in eine Liste von Schlüssel-Wert-Paaren um. Diese Paare werden dann nach Schlüsseln sortiert und an den Reduce-Schritt weitergegeben. Der Reduce-Schritt aggregiert die Daten auf der Grundlage der Schlüssel und generiert die Ausgabe.

Das MapReduce-Modell ermöglicht es, Daten auf mehreren Computern parallel zu verarbeiten, wodurch die Gesamtdurchlaufzeit deutlich verkürzt wird. Da jeder Schritt des Prozesses auf verschiedenen Computern ausgeführt wird, kann das Framework große Datenmengen effizient verarbeiten, ohne dass es zu Überlastungen oder Performance-Problemen kommt.

### Apache Kafka
Apache Kafka ist eine Open-Source-Plattform für die Datenverarbeitung und -integration. Es wurde für die Verarbeitung von hochvolumigen, schnelllaufenden Datenströmen entwickelt und ist eines der führenden Tools für das Stream-Processing.

Kafka arbeitet nach einem Publish-Subscribe-Modell, bei dem Clients (Publisher) Daten in Form von Nachrichten an ein oder mehrere Themen (Topics) senden können und andere Clients (Subscriber) diese Nachrichten abonnieren und verarbeiten können. Dieses Modell ermöglicht es, Daten in Echtzeit zu sammeln, zu verarbeiten und zu verteilen.

Kafka verwendet ein horizontal skalierbares Cluster-Modell, bei dem mehrere Server miteinander verbunden sind, um eine hohe Verfügbarkeit und Fehlertoleranz zu gewährleisten. Es unterstützt auch die Verarbeitung von Datenströmen in Batches und verfügt über eine integrierte Verwaltung für Fehlertoleranz und Datensicherheit.

### Kubernetes 
Kubernetes ist ein Open-Source-System zur Automatisierung der Deployment, Skalierung und Verwaltung von Anwendungen in Containern. Es ist ein weit verbreiteter Standard für die Orchestrierung von Microservices-Anwendungen und bietet eine Plattformunabhängige Umgebung, die es Entwicklern ermöglicht, ihre Anwendungen auf eine Vielzahl von Hosts auszuführen, einschließlich On-Premises-Datenzentren, der Cloud und Hybridumgebungen.

### Data warehouse vs data lake
Datawarehouse und Data Lake sind beides Lösungen zur Datenspeicherung und Analyse, aber sie haben einige wichtige Unterschiede:

- Zweck: Ein Datawarehouse wird verwendet, um geschäftskritische Daten zu sammeln, zu integrieren und zu analysieren, während ein Data Lake dazu dient, große Mengen an unstrukturierten und semi-strukturierten Daten zu speichern und zu analysieren, ohne dass sie vorher in einer bestimmten Struktur organisiert werden müssen.

- Datenformate: Ein Datawarehouse verwendet normalerweise ein starres Schema, das vor der Speicherung von Daten definiert wird. Ein Data Lake hingegen speichert Daten in ihrem ursprünglichen Format und ermöglicht es Benutzern, Daten in einem beliebigen Format hinzuzufügen, wodurch eine größere Flexibilität und eine einfachere Datenaufnahme ermöglicht wird.

- Datenqualität: In einem Datawarehouse werden Daten normalerweise vor der Speicherung bereinigt und bereinigt, um eine hohe Datenqualität sicherzustellen. Ein Data Lake speichert hingegen alle Daten, einschließlich möglicher Duplikate und fehlerhafter Daten, die später bereinigt werden können.

- Performance: Ein Datawarehouse ist in der Regel schneller als ein Data Lake bei der Durchführung von Abfragen, da es über ein starres Schema verfügt und speziell für Abfragen optimiert ist. Ein Data Lake ist jedoch besser geeignet für Big-Data-Analysen und Machine-Learning-Anwendungen, die größere Datenmengen benötigen.

- Kosten: Ein Datawarehouse kann teurer sein als ein Data Lake, da es normalerweise über eine hochleistungsfähige Hardware und eine umfassendere Infrastruktur verfügt, um schnelle Abfragen und Analysen durchzuführen. Ein Data Lake verwendet hingegen normalerweise günstigere Speicheroptionen, wie z.B. Cloud-basierte Lösungen, um Kosten zu sparen.

### Die 5 Vs
Die 5 Vs der Datenverarbeitung sind die fünf Merkmale, die große Datenmengen (Big Data) kennzeichnen:

- Volume: Bezieht sich auf die massive Menge an Daten, die aus verschiedenen Quellen wie sozialen Medien, IoT-Geräten, Transaktionen und mehr generiert werden.

- Varity: Bezieht sich auf die verschiedenen Typen von Daten wie strukturierten, unstrukturierten und semi-strukturierten Daten.

- Velocity: Bezieht sich auf die Geschwindigkeit, mit der Daten generiert und verarbeitet werden müssen, um Wert aus ihnen zu extrahieren.

- Veracity: Bezieht sich auf die Genauigkeit, Vollständigkeit und Konsistenz der Daten.

- Value: Bezieht sich auf die Einsichten und Intelligenz, die aus der Analyse der Daten gewonnen werden können, um Entscheidungen zu unterstützen und Geschäftswert zu schaffen.


### BI vs Data Analytics
- Business Intelligence (BI) ist ein Ansatz zur Verwaltung und Analyse von Geschäftsdaten, um bessere Entscheidungen zu treffen. BI umfasst Technologien, Prozesse und Methoden zur Datensammlung, -bereinigung, -analyse und -darstellung, um Einblicke in das Geschäft zu gewinnen. BI-Tools bieten eine visuelle Darstellung von Daten, um Trends, Muster und Beziehungen zu identifizieren.

- Data Analytics ist ein Ansatz zur Analyse von Daten, um Muster, Trends und Vorhersagen zu erkennen. Es konzentriert sich auf die Analyse von Daten, um Wissen zu gewinnen und bessere Entscheidungen zu treffen. Data Analytics beinhaltet die Verwendung von Methoden und Technologien wie statistische Analyse, Machine Learning und Datenmining, um Daten zu verstehen und Prozesse zu verbessern.

## VWL

### Marktversagen nach Musgrave:
- Allokation:
Mit vorhandenen Produktionsfaktoren soll ein Maximum an
Gütern (inkl. Dienstleistungen) in Abstimmung mit der Nachfrage (→ optimale Bedürfnisbefriedigung) geschaffen werden.
→ ökonomisches Prinzip (Maximalprinzip)
→ Transformationskurve
-  Distribution:
In einer Marktwirtschaft erfolgt die Verteilung der Einkommen
grundsätzlich nach dem Leistungsprinzip.
Allerdings bleiben dadurch bestimmte Personengruppen ohne
Einkommen. Zudem stellt sich die Frage, ob die Marktverteilung immer leistungsgerecht ist (→ Startchancengleicheit?).
- Stabilisierung:
Die historischen Erfahrungen zeigen, dass es in Marktwirtschaften regelmäßig zu Wirtschaftskrisen mit hoher Arbeitslosigkeit kommt.
Gemäß der keynesianischen Konjunkturtheorie sollen die
Konjunkturschwankungen durch staatliche Aktivitäten ausgeglichen werden.
→ antizyklische Geld- und Fiskalpolitik

### Ursachen für Staatsversagen:
- Informations- und Entscheidungsproblem:
• Überforderung angesichts einer Vielzahl von Informationen
• langwierige Entscheidungsverfahren (→ Föderalismus)
→ staatliche Maßnahmen tw. falsch dosiert und zu spät
- Kontroll- und Bewertungsproblem:
• unzureichende Kontroll- und Sanktionsmechanismen
• keine Marktbewertung öffentlicher Leistungen
→ ineffiziente Verwendung öffentlicher Mittel
- Wettbewerbsproblem:
Wenn der Staat aktiv in das Wirtschaftsgeschehen eingreift,
hat er häufig eine überragende Marktstellung (z.B. Bahn,
Post, Bundesagentur für Arbeit). Gemäß der mikroökonomischen Theorie führen starke Marktstellungen aber häufig
nicht zu gesamtwirtschaftlich optimalen Ergebnissen.
- Interessenproblem:
• Eigeninteressen von Politikern/Parteien
• Eigeninteressen der Bürokratie
→ Ökonomische Theorie der Politik zeigt, dass politische
Entscheidungen vor allem bei langfristigen Themen nicht
immer volkswirtschaftlich sinnvoll sind.

### Magisches (Sechs-)Viereick:
Dient als Maßstab zu Wohlfahrtsmaximierung

- Stabilität des Preisniveaus:
• Durchschnitt der Preise (nicht einzelne Preise) konstant
• Preisindex für die Lebenshaltung
• repräsentativer Warenkorb
• Laspeyres-Index
- hoher Beschäftigungsstand:
• möglichst geringe Arbeitslosenquote
• international sehr unterschiedliche Messmethoden
• Ziel Vollbeschäftigung gilt als unrealistisch
• weitere Indikatoren: offene Stellen, Beschäftigtenzahl
- außenwirtschaftliches Gleichgewicht:
• Saldo der Leistungsbilanz (= Teil der Zahlungsbilanz) = 0
• wenn Ungleichgewicht, dann besser leichter Überschuss
• Überschüsse einer Nation sind Defizite anderer Nationen
- stetiges und angemessenes Wachstum:
• gleichmäßige Erhöhung des realen BIPs
• BIP als Indikator sehr umstritten → qualitatives Wachstum
• zudem zahlreiche Messprobleme
- gerechte Einkommens- und Vermögensverteilung:
• Korrektur der primären Verteilung (= Marktverteilung)
• Lorenzkurve und Gini-Koeffizient
• Werturteil: Was ist „gerecht“?
- Umweltschutz:
• Prinzip der Nachhaltigkeit (ökologisches Gleichgewicht)
• Kennziffern der Umweltökonomischen Gesamtrechnung
• Werturteil: Was ist eine „angemessene Umweltqualität“?


### Keynesianismus
Dies ist eine wirtschaftstheoretische Schule, die von John Maynard Keynes begründet wurde. Keynesianismus geht davon aus, dass Regierungen eine aktive Rolle in der Wirtschaftspolitik spielen sollten, um Konjunkturzyklen zu glätten und Arbeitslosigkeit zu reduzieren.

Im Keynesianismus wird die Nachfrage als entscheidender Faktor für die Wirtschaft betrachtet. Keynes argumentierte, dass während wirtschaftlicher Abschwünge die Regierung durch öffentliche Ausgaben und den Abbau von Steuern die Nachfrage erhöhen und so eine Konjunkturerholung fördern kann.

### Neoklassiche Theorie
Die neoklassische Theorie betont die Bedeutung von Angebot und Nachfrage für die Bestimmung von Preisen und Märkten. Es wird davon ausgegangen, dass sich der Markt durch die Interaktion von Käufern und Verkäufern selbst reguliert und zu einer effizienten Allokation von Ressourcen führt.

### Prinzipien der Umweltpolitik
- Verursacherprinzip:
Die Kosten zur Vermeidung, Beseitigung oder zum Ausgleich
von Umweltbelastungen trägt der Verursacher. Die negativen
externen Effekte (→ Umweltkosten) sind beim Verursacher
zu internalisieren (d.h. dieser soll sie in seiner Kostenrechnung berücksichtigen).
- Gemeinlastprinzip:
Der Staat übernimmt die notwendigen Maßnahmen zur Vermeidung bzw. Beseitigung von Umweltschäden. Die Finanzierung der Umweltmaßnahmen erfolgt über die Gemeinschaft (= Steuerzahler). 
- Kooperationsprinzip:
Mitwirkung und Mitverantwortlichkeit aller Betroffenen (z.B.
Unternehmen, Haushalte, Industrie- und Verbraucherverbände, Parteien)
Durch die Kooperation sollen praktikable und allgemein
akzeptierte Lösungen für Umweltprobleme gefunden werden.
Gleichzeitig soll damit das Umweltbewusstsein gefördert
werden.
- Vorsorgeprinzip:
Umweltpolitische Entscheidungen und Maßnahmen sind so
zu treffen, dass möglichst von vornherein Umweltgefahren
und Umweltschäden vermieden werden.
Hinter diesem Prinzip steht der Gedanke der Nachhaltigkeit
und damit das Ziel den Bestand an natürlichen Ressourcen
auch für künftige Generationen zu bewahren.

### Protektinismus
Protektionismus ist eine wirtschaftspolitische Strategie, bei der ein Land den Handel mit anderen Ländern einschränkt oder reguliert, um seine eigene Wirtschaft zu schützen oder zu fördern. Dies kann erreicht werden, indem Handelsbarrieren, wie Zölle und Quoten, eingeführt werden, um den Import von Waren und Dienstleistungen aus dem Ausland zu beschränken. Die Idee ist, dass durch den Schutz der heimischen Industrien vor Konkurrenz aus dem Ausland, die heimische Wirtschaft gestärkt wird.

Es gibt jedoch auch Kritik an dieser Strategie, da sie den Handel und die Wirtschaftskraft auf internationaler Ebene beeinträchtigen kann. Auch kann der Protektionismus zu einer Verteuerung der Waren und Dienstleistungen für Verbraucher führen, wenn diese nicht mehr aus dem Ausland importiert werden können.

### Globalisierung
Globalisierungsteht für die zunehmende Internationalisierung
von Märkten für Waren und Dienstleistungen, von Finanzmärkten sowie von Unternehmen und Branchen
- Vorteile: 
positive Wohlfahrtseffekte gemäß der Theorie der komparativen Kostenvorteile für alle am Welthandel beteiligten
Länder durch Arbeitsteilung und Gütertausch
• viele Güter nur durch Außenhandel verfügbar
• Förderung der politischen Integration und Demokratisierung durch wirtschaftliche Öffnung
- Nachteile:
• Größenvorteile werden wichtiger → Monopolisierungstendenzen → Wettbewerbsprobleme
• verstärkter Strukturwandel → erhöhte berufliche und
regionale Flexibilität nötig
• Umweltdumping und Sozialdumping
• Abhängigkeit von anderen Nationen wegen Außenhandel
→ problematisch bei politischen Krisen
• mehr Transporte durch verstärkten Güter- und Personenverkehr → Verkehrsinfarkt und steigende Umweltbelastung
• Destabilisierung der Finanzmärkte durch Spekulation,
Arbitrage und große Leistungsbilanzungleichgewichte

### Stufen der regionalen Liberalisierung
1) Freihandelszone
2) Zollunion
3) Gemeinsamer Markt
4) Wirtschaftsunion
5) Wirtschafts- und Währungsunion
6) Politische Union

## Projektmanagment

### Projekt
Charakterstiken:
- Einmalig
- Komplex
- Neuartig
- Veränderung

Phasen: Initierung, Planung, Durchführung, Abschluss

### Machbarkeitsstudie
1. Ressourcen suchen und bereitstellen
2. Planung der Studie
3. Durchführung der Studie
4. Auswertung/Aufbereitung Datenmaterial
5. Präsentation erstellen und verteilen
6. Entscheidung

### Anforderungsermittlung
User-Stories mit INVEST-Prinzip:

- Independent: Beschreibung ist nicht von anderer Beschreibung abhängig
- Negotiable: Beschreibung dient als Gesprächsgrundlage, Entwicklung mögl.
- Valuable: Beschreibung zeigt immer Vorteil für den User / Auftraggeber
- Estimatable: Beschreibung ist schätzbar (ausreichend viele Details)
- Small: Beschreibung ist klein genug, um in einer Iteration bearbeitet zu werden
- Testable: Ableitung von Testfällen möglich aus den Akzeptanzkriterien heraus

Stakeholderanalyse:

Ermittle:
- Stakeholder
- Erwartungen der Stakeholder
- Einstellung der Stakeholder
- Einfluss der Stakeholder
- Maßnahmen

### Teamentwicklungsphasen
- Forming: kennenlernen
- Storming: unterschwellige Konflikte
- Norming: offene Konfrontationen, Enwicklung von Regeln
- Performing: ideenreich, produktiv, flexibel
- Adjourning: Auflösung des Teams

### Projektstrukturansätze
- Objektorientiere Zerlegung
- Funktionsorientierte Zerlegung
- Phasen- oder zeitorientierte Zerlegung

### Chancen und Risiken
Abstufungen der Handlungsmöglichkeiten
Chancen:
- Ergreifen
- Fördern
- Übertragen
- Abwarten

Risiken:
- Vermeiden
- Verringern
- Abwälzen
- Übernehmen

### Scaling Agile
- Scaled Agile Framework (SAFe):
Beinhaltet Organisations- und Workflow-Muster zur Implementierung von agilen Praktiken
im gesamten Unternehmen (inkl. Leitlinien zu Rollen, Verantwortlichkeiten, Planung und
Verwaltung von Aufgaben, Werten)
- Large Scale Scrum (LeSS):
--> Skalierung des „Wie“ – d.h. Skalierung von Entwicklern & Scrum Master
(keine Product Owner-Hierarchie, ein PO arbeitet mit mehreren Teams zusammen)
--> Voraussetzungen: sehr „reife“ Scrum Teams, kein Projektmanagementparadigma
- Nexus:
– Skalierung von Scrum-Projekten mit 3 bis 9 Teams
– Alle beteiligten Teams arbeiten nach der Scrum Methode
– Einführung zusätzlicher Rollen für die Koordination der Teams
– Ziel: Reduzierung von Komplexität & Abhängigkeiten unter den Teams
-> Minimierung der Skalierungsherausforderungen

## Operations Research
### Lineare Programme
Ein lineares Programm besteht aus einer Zielfunktion, die einen linearen Ausdruck darstellt, und einer Reihe von linearen Beschränkungen, die ebenfalls lineare Ausdrücke darstellen.

Das Ziel bei einem linearen Programm ist es, eine bestimmte Größe, wie z.B. den Gewinn oder die Kosten, zu maximieren oder zu minimieren, während die vorhandenen Ressourcen und andere Beschränkungen berücksichtigt werden. Lineare Programme finden häufig Anwendung in Bereichen wie Produktion, Finanzen, Logistik und Marketing. Lineare Programme können analytisch oder numerisch gelöst werden.

### Simplex-Methode
Die Simplex-Methode arbeitet, indem sie in jedem Schritt die linearen Beschränkungen überprüft und eine neue Basislösung berechnet, bis eine optimale Lösung gefunden wird oder alle Möglichkeiten ausgeschöpft sind.

In jedem Schritt wird eine lineare Kombination aus den Basisvariablen berechnet, um diejenige zu identifizieren, die das Ziel (maximieren oder minimieren) am besten verbessert. Diese Variable wird aus der Basis ausgeschlossen und durch eine neue Variable ersetzt, die die entsprechenden linearen Beschränkungen erfüllt. Dieser Prozess wird fortgesetzt, bis keine weiteren Verbesserungen mehr möglich sind oder eine optimale Lösung gefunden wurde.

### Dualität
Die Dualität ist ein Konzept im Operations Research, das die Beziehung zwischen zwei linearen Optimierungsproblemen beschreibt. Ein lineares Optimierungsproblem kann entweder als Primalfunktion (auch bekannt als Zielproblem) oder als Dualfunktion (auch bekannt als Dualproblem) formuliert werden.

Primalfunktionen sind Probleme, die eine lineare Funktion zu maximieren oder zu minimieren unter einer Reihe von linearen Beschränkungen haben. Dualfunktionen sind Probleme, die die gleichen Beschränkungen haben, aber die Funktion ist eine lineare Kombination aus den Koeffizienten der Beschränkungen.

Wichtig ist, dass jede Lösung eines Primals eine entsprechende Lösung des Duals und umgekehrt hat. Daher kann man manchmal das Primal- oder das Dualproblem lösen, um die Lösung des anderen Problems zu erhalten.

### Graphentheorie
Knoten (auch bekannt als Vertex): Ein Knoten repräsentiert einen Punkt in einem Graph.
Kante (auch bekannt als Edge): Eine Kante verbindet zwei Knoten und repräsentiert eine Verbindung zwischen ihnen.
Adjazenz: Zwei Knoten sind adjazent, wenn sie durch eine Kante verbunden sind.
Grad: Der Grad eines Knotens ist die Anzahl der Kanten, die mit ihm verbunden sind.
Pfad: Ein Pfad ist eine Folge von Knoten und Kanten, die in einer Reihenfolge miteinander verbunden sind.
Kreis: Ein Kreis ist ein Pfad, bei dem der Anfangsknoten und der Endknoten identisch sind.
Ungerichteter Graph: Ein ungerichteter Graph ist ein Graph, bei dem die Kanten keine Richtung haben.
Gerichteter Graph: Ein gerichteter Graph ist ein Graph, bei dem die Kanten eine Richtung haben.
Zusammenhang: Ein Graph ist zusammenhängend, wenn es zwischen jedem Knoten einen Pfad gibt.

### Minimaler Spannbaum
Minimale Spannbäume sind in der Graphentheorie eine Art von Spannbäumen, bei denen das Gewicht des Baums minimiert wird, indem es die kürzesten Kanten zwischen den Knoten auswählt. Ein Minimaler Spannbaum ist ein Baum, der alle Knoten in einem Graph enthält und bei dem das Gesamtgewicht der Kanten minimal ist.

### Kürzeste Wege
ALgorrithmen:
- Dijkstra
- Algorithmus von Bellmann und Ford
- Algorithmus von Floyd und Warshall

### Maximaler Fluss
Ein maximaler Fluss ist ein Konzept in der Netzwerktheorie und bezieht sich auf die größtmögliche Menge an Daten oder Material, die durch ein Netzwerk von Quellen zu Zielen fließen kann. Ein maximaler Fluss definiert eine obere Grenze für den Datenfluss, die auf die Kapazitäten der Kanten im Netzwerk beschränkt ist.

Die Lösung des Problems des maximalen Flusses besteht darin, die optimale Route für den Datenfluss zu finden, um die Kapazität jeder Kante voll auszunutzen. Diese Technik wird häufig in Bereichen wie Transport, Logistik und Netzwerkplanung eingesetzt.

### Residualnetz
Ein Residualnetz stellt die verbleibenden Kapazitäten der Kanten im Netzwerk dar, nachdem ein Teil des Flusses bereits durch das Netzwerk geflossen ist. Diese verbleibenden Kapazitäten werden als Residualkapazitäten bezeichnet. Durch die Analyse des Residualnetzes kann man erkennen, welche Kanten des Netzwerkes noch Kapazität für zusätzlichen Fluss haben und welche Kanten bereits vollständig ausgelastet sind.

### Ganzzahlige Programmierung
Die Ganzzahlige Programmierung (Integer Programming) ist eine spezielle Form der linearen Programmierung, bei der einige oder alle Variablen nur ganzzahlige Werte annehmen dürfen

## Network Analysis
### Grundbegriffe
- Knoten (auch bekannt als Vertex): Ein Knoten repräsentiert einen Punkt in einem Graph.
- Kante (auch bekannt als Edge): Eine Kante verbindet zwei Knoten und repräsentiert eine Verbindung zwischen ihnen.
- Adjazenz: Zwei Knoten sind adjazent, wenn sie durch eine Kante verbunden sind.
- Grad: Der Grad eines Knotens ist die Anzahl der Kanten, die mit ihm verbunden sind.
- Pfad: Ein Pfad ist eine Folge von Knoten und Kanten, die in einer Reihenfolge miteinander verbunden sind.
- Kreis: Ein Kreis ist ein Pfad, bei dem der Anfangsknoten und der Endknoten identisch sind.
- Ungerichteter Graph: Ein ungerichteter Graph ist ein Graph, bei dem die Kanten keine Richtung haben.
- Gerichteter Graph: Ein gerichteter Graph ist ein Graph, bei dem die Kanten eine Richtung haben.
- Gewichtung: Eine Kante kann eine Wichtung haben, die ihre Bedeutung oder Priorität darstellt.
- Zusammenhang: Ein Graph ist zusammenhängend, wenn es zwischen jedem Knoten einen Pfad gibt.

----------------------
OLTP vs OLAP wichtig für Bachelorprüfung
